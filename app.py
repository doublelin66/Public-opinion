import streamlit as st
import google.generativeai as genai
import feedparser
import requests
import json
import pandas as pd
from datetime import datetime
import urllib.parse

# ================= 1. åŸºç¤è¨­å®š =================
st.set_page_config(
    page_title="ğŸ‡¹ğŸ‡¼è‡ºç£ç†±é–€è¨è«–",
    page_icon="ğŸ”¥",
    layout="wide"
)

# ================= 2. å®‰å…¨è®€å–é‡‘é‘° =================
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
except:
    st.error("âš ï¸ æ‰¾ä¸åˆ°é‡‘é‘°ï¼è«‹ç¢ºèª Streamlit Secrets è¨­å®šã€‚")
    st.stop()

genai.configure(api_key=API_KEY)

# ================= 3. æ ¸å¿ƒåŠŸèƒ½ï¼šå¼·å›ºå‹ AI åˆ†æ =================
@st.cache_data(ttl=1800)
def run_analysis():
    # --- A. æ¨¡å‹èˆ‡å®‰å…¨è¨­å®š (é—œéµä¿®æ­£) ---
    # 1. è§£é™¤å®‰å…¨é™åˆ¶ï¼Œé¿å…æ–°èå› ç‚ºæ”¿æ²»/ç¤¾æœƒè­°é¡Œè¢«éæ¿¾
    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]
    
    # 2. å¼·åˆ¶è¼¸å‡º JSON æ ¼å¼ (é€™æ˜¯ 1.5/2.5 æ¨¡å‹çš„æ–°åŠŸèƒ½ï¼Œå¤§å¹…é™ä½æ ¼å¼éŒ¯èª¤)
    generation_config = {
        "temperature": 1,
        "response_mime_type": "application/json"
    }

    model_name = 'gemini-2.5-flash'
    try:
        model = genai.GenerativeModel(model_name, safety_settings=safety_settings, generation_config=generation_config)
    except:
        # å¦‚æœ 2.5 é€£ç·šå¤±æ•—ï¼Œå›é€€åˆ° Pro (ä¸ä½¿ç”¨ JSON Mode ä»¥å…èˆŠç‰ˆä¸æ”¯æ´)
        model = genai.GenerativeModel('gemini-pro', safety_settings=safety_settings)

    # --- B. å®šç¾©ä¾†æº ---
    rss_sources = {
        "ğŸ”¥ æœå°‹ç†±æ¦œ": "https://trends.google.com/trends/trendingsearches/daily/rss?geo=TW",
        "ğŸ¿ å¨›æ¨‚": "https://news.google.com/rss/topics/CAAqKggKIiRDQkFTRlFvSUwyMHZNREpxYW5RU0FBUWlHZ0pKVERNU0FBUW?hl=zh-TW&gl=TW&ceid=TW%3Azh-Hant",
        "ğŸ“° ç¶œåˆ": "https://news.google.com/rss?hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    }
    
    all_raw_data = []
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}

    for category_name, url in rss_sources.items():
        try:
            response = requests.get(url, headers=headers, timeout=10)
            feed = feedparser.parse(response.content)
            
            limit = 20 if "æœå°‹" in category_name else 10
            
            for entry in feed.entries[:limit]:
                traffic = "N/A"
                if hasattr(entry, 'ht_approx_traffic'):
                    traffic = entry.ht_approx_traffic
                
                all_raw_data.append({
                    "source": category_name,
                    "title": entry.title,
                    "traffic": traffic,
                    "snippet": entry.summary if hasattr(entry, 'summary') else ""
                })
        except Exception as e:
            continue

    if not all_raw_data:
        return []

    # --- C. AI åˆ†æ ---
    news_json = json.dumps(all_raw_data, ensure_ascii=False)

    prompt = f"""
    ä½ æ˜¯ä¸€å€‹å°ç£ç¤¾ç¾¤è¶¨å‹¢è§€å¯Ÿå®¶ã€‚è«‹åˆ†æä»¥ä¸‹è³‡æ–™ä¸¦æ•´ç†å‡º **15-20 å€‹** å°ç£ç¾åœ¨æœ€ç†±é–€çš„è¨è«–è©±é¡Œã€‚

    åŸå§‹è³‡æ–™ï¼š
    {news_json}
    
    è¦æ±‚ï¼š
    1. ä¸»é¡Œè¦å¤šå…ƒ (æ”¿æ²»/å¨›æ¨‚/é‹å‹•/ç”Ÿæ´»)ã€‚
    2. æœ‰æµé‡æ•¸æ“š (å¦‚ "50,000+") åˆ†æ•¸çµ¦é«˜ã€‚
    3. ç¹é«”ä¸­æ–‡æ‘˜è¦ã€‚
    
    è«‹ç›´æ¥å›å‚³ JSON Arrayï¼š
    [
      {{
        "id": 1,
        "keyword": "è©±é¡Œé—œéµå­—",
        "category": "åˆ†é¡ (Entertainment, Sports, Politics, Tech, Life)",
        "score": 95,
        "volume_label": "è¨è«–é‡ç´š (å¦‚: 5è¬+ æœå°‹)",
        "summary": "ç°¡çŸ­èªªæ˜ã€‚",
        "hashtags": ["#tag1"]
      }}
    ]
    """
    
    try:
        response = model.generate_content(prompt)
        
        # å³ä½¿æœ‰ JSON Modeï¼Œé‚„æ˜¯åšä¸€ä¸‹å­—ä¸²æ¸…ç†æ¯”è¼ƒä¿éšª
        cleaned_text = response.text.replace("```json", "").replace("```", "").strip()
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºç©º (AI æ‹’çµ•å›ç­”æ™‚æœƒç™¼ç”Ÿ)
        if not cleaned_text:
            st.warning("AI å›å‚³ç©ºç™½å…§å®¹ï¼Œå¯èƒ½æ˜¯è§¸ç™¼å®‰å…¨æ©Ÿåˆ¶ï¼Œè«‹ç¨å¾Œé‡è©¦ã€‚")
            return []
            
        return json.loads(cleaned_text)
    except Exception as e:
        # å°å‡ºéŒ¯èª¤èˆ‡åŸå§‹æ–‡å­—ï¼Œæ–¹ä¾¿é™¤éŒ¯
        st.error(f"AI åˆ†æå¤±æ•—: {e}")
        # å¦‚æœæƒ³çœ‹ AI åˆ°åº•å›äº†ä»€éº¼é¬¼æ±è¥¿ï¼Œå¯ä»¥æŠŠä¸‹é¢é€™è¡Œå–æ¶ˆè¨»è§£
        # st.text(response.text if 'response' in locals() else "No Response")
        return []

# ================= 4. ä»‹é¢é¡¯ç¤º (UI) =================
col1, col2 = st.columns([3, 1])
with col1:
    st.title("ğŸ‡¹ğŸ‡¼è‡ºç£ç†±é–€è¨è«–")
    st.caption(f"é»æ“Šå¡ç‰‡å¯æŸ¥çœ‹ç›¸é—œæ–°è | æ›´æ–°: {datetime.now().strftime('%H:%M')}")

with col2:
    if st.button("ğŸ”„ åˆ·æ–°ç†±æ¦œ"):
        st.cache_data.clear()
        st.rerun()

st.divider()

with st.spinner('ğŸ” æ­£åœ¨æŒ–æ˜å…¨å°ç†±æœèˆ‡ç¤¾ç¾¤è©±é¡Œ...'):
    trends = run_analysis()

if trends:
    st.markdown("""
    <style>
        a.trend-link { text-decoration: none !important; color: inherit !important; display: block; }
        .trend-row { background-color: white; padding: 15px; border-radius: 10px; margin-bottom: 12px; border: 1px solid #eee; transition: all 0.2s ease; cursor: pointer; }
        .trend-row:hover { transform: translateY(-2px); box-shadow: 0 5px 15px rgba(0,0,0,0.1); border-color: #FF4B4B; }
        .rank-num { font-size: 1.5em; font-weight: bold; color: #ccc; width: 40px; text-align: center; }
        .rank-1 { color: #FF4B4B; }
        .rank-2 { color: #FF8F00; }
        .rank-3 { color: #FFC107; }
        .volume-badge { background-color: #ffebee; color: #c62828; padding: 3px 8px; border-radius: 12px; font-size: 0.8em; font-weight: bold; }
        .category-badge { background-color: #f1f3f4; color: #555; padding: 3px 8px; border-radius: 4px; font-size: 0.8em; }
    </style>
    """, unsafe_allow_html=True)

    st.subheader("ğŸ“Š è©±é¡Œç†±åº¦åˆ†ä½ˆ")
    df = pd.DataFrame(trends)
    if not df.empty:
        st.bar_chart(df.set_index('keyword')['score'], color="#FF4B4B")

    st.subheader("ğŸ† å…¨å°è©±é¡Œæ’è¡Œæ¦œ (é»æ“Šå¯çœ‹æ–°è)")
    
    for i, item in enumerate(trends):
        rank_class = f"rank-{i+1}" if i < 3 else ""
        search_query = urllib.parse.quote(item['keyword'])
        google_url = f"https://www.google.com/search?q={search_query}"
        
        st.markdown(f"""
        <a href="{google_url}" target="_blank" class="trend-link">
            <div class="trend-row">
                <div style="display:flex; align-items:center;">
                    <div class="rank-num {rank_class}">{i+1}</div>
                    <div style="flex-grow:1; padding-left:15px;">
                        <div style="display:flex; justify-content:space-between; align-items:center;">
                            <h3 style="margin:0; font-size:1.2em; color:#333;">{item['keyword']} ğŸ”—</h3>
                            <span class="volume-badge">ğŸ”¥ {item.get('volume_label', 'ç†±è­°ä¸­')}</span>
                        </div>
                        <div style="margin-top:5px; font-size:0.9em; color:#666;">
                            <span class="category-badge">{item['category']}</span>
                            <span style="margin-left:8px;">{item['summary']}</span>
                        </div>
                        <div style="margin-top:8px; font-size:0.85em; color:#888;">
                            {' '.join([f'#{tag}' for tag in item.get('hashtags', [])]).replace('##', '#')}
                        </div>
                    </div>
                </div>
            </div>
        </a>
        """, unsafe_allow_html=True)

else:
    st.info("ç›®å‰ç„¡æ³•å–å¾—è³‡æ–™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
