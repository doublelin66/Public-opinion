import streamlit as st
import google.generativeai as genai
import feedparser
import requests
import json
import pandas as pd
from datetime import datetime
import urllib.parse # æ–°å¢é€™å€‹åº«ï¼Œç”¨ä¾†è™•ç†ç¶²å€ç·¨ç¢¼

# ================= 1. åŸºç¤è¨­å®š =================
st.set_page_config(
    page_title="ğŸ‡¹ğŸ‡¼è‡ºç£ç†±é–€è¨è«–",
    page_icon="ğŸ”¥",
    layout="wide"
)

# ================= 2. å®‰å…¨è®€å–é‡‘é‘° =================
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
except:
    st.error("âš ï¸ æ‰¾ä¸åˆ°é‡‘é‘°ï¼è«‹ç¢ºèª Streamlit Secrets è¨­å®šã€‚")
    st.stop()

genai.configure(api_key=API_KEY)

# ================= 3. æ ¸å¿ƒåŠŸèƒ½ï¼šæœå°‹è¶¨å‹¢ + æ–°èçˆ¬èŸ² =================
@st.cache_data(ttl=1800) # 30 åˆ†é˜æ›´æ–°ä¸€æ¬¡
def run_analysis():
    # --- A. æ¨¡å‹è¨­å®š ---
    model_name = 'gemini-2.5-flash'
    try:
        model = genai.GenerativeModel(model_name)
    except:
        model = genai.GenerativeModel('gemini-pro')

    # --- B. å®šç¾©ä¾†æº ---
    rss_sources = {
        "ğŸ”¥ æœå°‹ç†±æ¦œ": "https://trends.google.com/trends/trendingsearches/daily/rss?geo=TW",
        "ğŸ¿ å¨›æ¨‚": "https://news.google.com/rss/topics/CAAqKggKIiRDQkFTRlFvSUwyMHZNREpxYW5RU0FBUWlHZ0pKVERNU0FBUW?hl=zh-TW&gl=TW&ceid=TW%3Azh-Hant",
        "ğŸ“° ç¶œåˆ": "https://news.google.com/rss?hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    }
    
    all_raw_data = []
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}

    for category_name, url in rss_sources.items():
        try:
            response = requests.get(url, headers=headers, timeout=10)
            feed = feedparser.parse(response.content)
            
            limit = 20 if "æœå°‹" in category_name else 10
            
            for entry in feed.entries[:limit]:
                traffic = "N/A"
                if hasattr(entry, 'ht_approx_traffic'):
                    traffic = entry.ht_approx_traffic
                
                all_raw_data.append({
                    "source": category_name,
                    "title": entry.title,
                    "traffic": traffic,
                    "snippet": entry.summary if hasattr(entry, 'summary') else ""
                })
        except Exception as e:
            continue

    if not all_raw_data:
        return []

    # --- C. AI åˆ†æ ---
    news_json = json.dumps(all_raw_data, ensure_ascii=False)

    prompt = f"""
    ä½ æ˜¯ä¸€å€‹å°ç£ç¤¾ç¾¤è¶¨å‹¢è§€å¯Ÿå®¶ã€‚è«‹åˆ†æä»¥ä¸‹ä¾†è‡ªã€ŒGoogle æœå°‹ç†±æ¦œã€èˆ‡ã€Œæ–°èã€çš„è³‡æ–™ã€‚
    ä½¿ç”¨è€…æƒ³çŸ¥é“ **ã€ŒğŸ‡¹ğŸ‡¼ å°ç£ç¾åœ¨æœ€ç†±é–€çš„è¨è«–æ˜¯ä»€éº¼ï¼Ÿã€**ã€‚

    åŸå§‹è³‡æ–™ï¼š
    {news_json}
    
    ğŸ”¥ ä»»å‹™æŒ‡ä»¤ï¼š
    1. **ä¸»é¡Œè¦å¤š**ï¼šè«‹åˆ—å‡º **15 åˆ° 20 å€‹** ä¸åŒçš„ç¨ç«‹è©±é¡Œã€‚
    2. **è©±é¡Œå¤šå…ƒ**ï¼šæ¶µè“‹ æ”¿æ²»ã€å¨›æ¨‚ã€é‹å‹•ã€ç”Ÿæ´»ã€è²¡ç¶“ã€‚
    3. **è¨è«–ç†±åº¦ä¼°ç®—**ï¼šä¾ç…§æµé‡æ•¸æ“šæˆ–æ–°èé‡è¦æ€§çµ¦åˆ† (0-100)ã€‚
    4. **ç¹é«”ä¸­æ–‡**ï¼šè«‹ç”¨å°ç£äººç¿’æ…£çš„ç”¨èªæ’°å¯« summaryã€‚

    è«‹åš´æ ¼éµå®ˆä»¥ä¸‹ JSON è¼¸å‡ºæ ¼å¼ (Array)ï¼Œç›´æ¥è¼¸å‡º JSONï¼š
    [
      {{
        "id": 1,
        "keyword": "è©±é¡Œé—œéµå­—",
        "category": "åˆ†é¡ (Entertainment, Sports, Politics, Tech, Life)",
        "score": 95,
        "volume_label": "è¨è«–é‡ç´š",
        "summary": "ç°¡çŸ­èªªæ˜ç‚ºä»€éº¼å¤§å®¶åœ¨è¨è«–é€™å€‹ã€‚",
        "hashtags": ["#tag1", "#tag2"]
      }}
    ]
    """
    
    try:
        response = model.generate_content(prompt)
        cleaned_text = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(cleaned_text)
    except Exception as e:
        st.warning(f"AI åˆ†æå¤±æ•—: {e}")
        return []

# ================= 4. ä»‹é¢é¡¯ç¤º (UI) =================
col1, col2 = st.columns([3, 1])
with col1:
    st.title("ğŸ‡¹ğŸ‡¼è‡ºç£ç†±é–€è¨è«–")
    st.caption(f"é»æ“Šå¡ç‰‡å¯æŸ¥çœ‹ç›¸é—œæ–°è | æ›´æ–°: {datetime.now().strftime('%H:%M')}")

with col2:
    if st.button("ğŸ”„ åˆ·æ–°ç†±æ¦œ"):
        st.cache_data.clear()
        st.rerun()

st.divider()

with st.spinner('ğŸ” æ­£åœ¨æŒ–æ˜å…¨å°ç†±æœèˆ‡ç¤¾ç¾¤è©±é¡Œ...'):
    trends = run_analysis()

if trends:
    st.markdown("""
    <style>
        /* è®“è¶…é€£çµå»é™¤åº•ç·šï¼Œä¸¦ä¿æŒé¡è‰² */
        a.trend-link {
            text-decoration: none !important;
            color: inherit !important;
            display: block;
        }
        
        .trend-row {
            background-color: white; 
            padding: 15px; 
            border-radius: 10px; 
            margin-bottom: 12px; 
            border: 1px solid #eee;
            transition: all 0.2s ease;
            cursor: pointer; /* è®“æ»‘é¼ è®Šæˆæ‰‹æŒ‡å½¢ç‹€ */
        }
        
        .trend-row:hover {
            transform: translateY(-2px); /* è¼•å¾®æµ®èµ· */
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
            border-color: #FF4B4B; /* é‚Šæ¡†è®Šè‰² */
        }

        .rank-num {
            font-size: 1.5em; 
            font-weight: bold; 
            color: #ccc; 
            width: 40px; 
            text-align: center;
        }
        .rank-1 { color: #FF4B4B; }
        .rank-2 { color: #FF8F00; }
        .rank-3 { color: #FFC107; }
        
        .volume-badge {
            background-color: #ffebee; 
            color: #c62828; 
            padding: 3px 8px; 
            border-radius: 12px; 
            font-size: 0.8em; 
            font-weight: bold;
        }
        .category-badge {
            background-color: #f1f3f4;
            color: #555;
            padding: 3px 8px;
            border-radius: 4px;
            font-size: 0.8em;
        }
    </style>
    """, unsafe_allow_html=True)

    # ä¸Šæ–¹åœ–è¡¨ (ä¿ç•™)
    st.subheader("ğŸ“Š è©±é¡Œç†±åº¦åˆ†ä½ˆ")
    df = pd.DataFrame(trends)
    if not df.empty:
        st.bar_chart(df.set_index('keyword')['score'], color="#FF4B4B")

    # æ’è¡Œæ¦œ
    st.subheader("ğŸ† å…¨å°è©±é¡Œæ’è¡Œæ¦œ (é»æ“Šå¯çœ‹æ–°è)")
    
    for i, item in enumerate(trends):
        rank_class = f"rank-{i+1}" if i < 3 else ""
        
        # è£½ä½œ Google æœå°‹é€£çµ
        # ä½¿ç”¨ urllib.parse.quote æŠŠä¸­æ–‡è½‰æˆç¶²å€ç·¨ç¢¼ (ä¾‹å¦‚ "å°ç©é›»" -> "%E5%8F%B0...")
        search_query = urllib.parse.quote(item['keyword'])
        google_url = f"https://www.google.com/search?q={search_query}"
        
        # ä½¿ç”¨ HTML <a> æ¨™ç±¤åŒ…ä½æ•´å€‹å¡ç‰‡ï¼Œtarget="_blank" ä»£è¡¨é–‹æ–°è¦–çª—
        st.markdown(f"""
        <a href="{google_url}" target="_blank" class="trend-link">
            <div class="trend-row">
                <div style="display:flex; align-items:center;">
                    <div class="rank-num {rank_class}">{i+1}</div>
                    <div style="flex-grow:1; padding-left:15px;">
                        <div style="display:flex; justify-content:space-between; align-items:center;">
                            <h3 style="margin:0; font-size:1.2em; color:#333;">{item['keyword']} ğŸ”—</h3>
                            <span class="volume-badge">ğŸ”¥ {item.get('volume_label', 'ç†±è­°ä¸­')}</span>
                        </div>
                        <div style="margin-top:5px; font-size:0.9em; color:#666;">
                            <span class="category-badge">{item['category']}</span>
                            <span style="margin-left:8px;">{item['summary']}</span>
                        </div>
                        <div style="margin-top:8px; font-size:0.85em; color:#888;">
                            {' '.join([f'#{tag}' for tag in item.get('hashtags', [])]).replace('##', '#')}
                        </div>
                    </div>
                </div>
            </div>
        </a>
        """, unsafe_allow_html=True)

else:
    st.info("å°šç„¡è³‡æ–™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
